{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Download traning data from open datasets\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])(torch.float32)\n",
      "Shape of y: torch.Size([64])(torch.int64)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "batch_size = 64\n",
    "\n",
    "# Create data loaders\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}({X.dtype})\")\n",
    "    print(f\"Shape of y: {y.shape}({y.dtype})\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training\n",
    "device = (\n",
    "    \"cuda\" if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flattern): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flattern = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flattern(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "    \n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss, optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define train func\n",
    "def train(\n",
    "        dataloader: DataLoader,\n",
    "        model: nn.Module,\n",
    "        loss_fn,\n",
    "        optimizer: torch.optim.Optimizer,\n",
    "    ):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test func\n",
    "def test(\n",
    "        dataloader: DataLoader,\n",
    "        model: nn.Module,\n",
    "        loss_fn,\n",
    "    ):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.358606 [   64/60000]\n",
      "loss: 0.487625 [ 6464/60000]\n",
      "loss: 0.306165 [12864/60000]\n",
      "loss: 0.536290 [19264/60000]\n",
      "loss: 0.460815 [25664/60000]\n",
      "loss: 0.477380 [32064/60000]\n",
      "loss: 0.484509 [38464/60000]\n",
      "loss: 0.660028 [44864/60000]\n",
      "loss: 0.606249 [51264/60000]\n",
      "loss: 0.437720 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.487211 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.355142 [   64/60000]\n",
      "loss: 0.485776 [ 6464/60000]\n",
      "loss: 0.304141 [12864/60000]\n",
      "loss: 0.533464 [19264/60000]\n",
      "loss: 0.457753 [25664/60000]\n",
      "loss: 0.475264 [32064/60000]\n",
      "loss: 0.482266 [38464/60000]\n",
      "loss: 0.658817 [44864/60000]\n",
      "loss: 0.604471 [51264/60000]\n",
      "loss: 0.435199 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.485573 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.351765 [   64/60000]\n",
      "loss: 0.483988 [ 6464/60000]\n",
      "loss: 0.302188 [12864/60000]\n",
      "loss: 0.530796 [19264/60000]\n",
      "loss: 0.454770 [25664/60000]\n",
      "loss: 0.473231 [32064/60000]\n",
      "loss: 0.480093 [38464/60000]\n",
      "loss: 0.657491 [44864/60000]\n",
      "loss: 0.602714 [51264/60000]\n",
      "loss: 0.432780 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.483988 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.348446 [   64/60000]\n",
      "loss: 0.482246 [ 6464/60000]\n",
      "loss: 0.300307 [12864/60000]\n",
      "loss: 0.528248 [19264/60000]\n",
      "loss: 0.451842 [25664/60000]\n",
      "loss: 0.471287 [32064/60000]\n",
      "loss: 0.477987 [38464/60000]\n",
      "loss: 0.656079 [44864/60000]\n",
      "loss: 0.600928 [51264/60000]\n",
      "loss: 0.430510 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.482448 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.345221 [   64/60000]\n",
      "loss: 0.480540 [ 6464/60000]\n",
      "loss: 0.298479 [12864/60000]\n",
      "loss: 0.525817 [19264/60000]\n",
      "loss: 0.449010 [25664/60000]\n",
      "loss: 0.469414 [32064/60000]\n",
      "loss: 0.475946 [38464/60000]\n",
      "loss: 0.654551 [44864/60000]\n",
      "loss: 0.599117 [51264/60000]\n",
      "loss: 0.428354 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.480953 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.342106 [   64/60000]\n",
      "loss: 0.478858 [ 6464/60000]\n",
      "loss: 0.296719 [12864/60000]\n",
      "loss: 0.523494 [19264/60000]\n",
      "loss: 0.446266 [25664/60000]\n",
      "loss: 0.467685 [32064/60000]\n",
      "loss: 0.473961 [38464/60000]\n",
      "loss: 0.653050 [44864/60000]\n",
      "loss: 0.597337 [51264/60000]\n",
      "loss: 0.426331 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.479494 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.339094 [   64/60000]\n",
      "loss: 0.477221 [ 6464/60000]\n",
      "loss: 0.294982 [12864/60000]\n",
      "loss: 0.521274 [19264/60000]\n",
      "loss: 0.443580 [25664/60000]\n",
      "loss: 0.465969 [32064/60000]\n",
      "loss: 0.472032 [38464/60000]\n",
      "loss: 0.651471 [44864/60000]\n",
      "loss: 0.595547 [51264/60000]\n",
      "loss: 0.424411 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.478059 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.336177 [   64/60000]\n",
      "loss: 0.475623 [ 6464/60000]\n",
      "loss: 0.293405 [12864/60000]\n",
      "loss: 0.519146 [19264/60000]\n",
      "loss: 0.440945 [25664/60000]\n",
      "loss: 0.464378 [32064/60000]\n",
      "loss: 0.470150 [38464/60000]\n",
      "loss: 0.649812 [44864/60000]\n",
      "loss: 0.593714 [51264/60000]\n",
      "loss: 0.422480 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.476665 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.333335 [   64/60000]\n",
      "loss: 0.474061 [ 6464/60000]\n",
      "loss: 0.291846 [12864/60000]\n",
      "loss: 0.517022 [19264/60000]\n",
      "loss: 0.438246 [25664/60000]\n",
      "loss: 0.462762 [32064/60000]\n",
      "loss: 0.468308 [38464/60000]\n",
      "loss: 0.648148 [44864/60000]\n",
      "loss: 0.591848 [51264/60000]\n",
      "loss: 0.420692 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.475313 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.330597 [   64/60000]\n",
      "loss: 0.472527 [ 6464/60000]\n",
      "loss: 0.290384 [12864/60000]\n",
      "loss: 0.514937 [19264/60000]\n",
      "loss: 0.435519 [25664/60000]\n",
      "loss: 0.461187 [32064/60000]\n",
      "loss: 0.466525 [38464/60000]\n",
      "loss: 0.646363 [44864/60000]\n",
      "loss: 0.589971 [51264/60000]\n",
      "loss: 0.418965 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.473991 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.327992 [   64/60000]\n",
      "loss: 0.470941 [ 6464/60000]\n",
      "loss: 0.288955 [12864/60000]\n",
      "loss: 0.512883 [19264/60000]\n",
      "loss: 0.432780 [25664/60000]\n",
      "loss: 0.459782 [32064/60000]\n",
      "loss: 0.464827 [38464/60000]\n",
      "loss: 0.644623 [44864/60000]\n",
      "loss: 0.588243 [51264/60000]\n",
      "loss: 0.417444 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.472717 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.325407 [   64/60000]\n",
      "loss: 0.469442 [ 6464/60000]\n",
      "loss: 0.287494 [12864/60000]\n",
      "loss: 0.510859 [19264/60000]\n",
      "loss: 0.430183 [25664/60000]\n",
      "loss: 0.458418 [32064/60000]\n",
      "loss: 0.463041 [38464/60000]\n",
      "loss: 0.643006 [44864/60000]\n",
      "loss: 0.586675 [51264/60000]\n",
      "loss: 0.416043 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.471472 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.322835 [   64/60000]\n",
      "loss: 0.468045 [ 6464/60000]\n",
      "loss: 0.286067 [12864/60000]\n",
      "loss: 0.508891 [19264/60000]\n",
      "loss: 0.427648 [25664/60000]\n",
      "loss: 0.457092 [32064/60000]\n",
      "loss: 0.461385 [38464/60000]\n",
      "loss: 0.641382 [44864/60000]\n",
      "loss: 0.585031 [51264/60000]\n",
      "loss: 0.414760 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.470247 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.320391 [   64/60000]\n",
      "loss: 0.466653 [ 6464/60000]\n",
      "loss: 0.284646 [12864/60000]\n",
      "loss: 0.507123 [19264/60000]\n",
      "loss: 0.425173 [25664/60000]\n",
      "loss: 0.455750 [32064/60000]\n",
      "loss: 0.459741 [38464/60000]\n",
      "loss: 0.639771 [44864/60000]\n",
      "loss: 0.583385 [51264/60000]\n",
      "loss: 0.413490 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.469046 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.318017 [   64/60000]\n",
      "loss: 0.465310 [ 6464/60000]\n",
      "loss: 0.283216 [12864/60000]\n",
      "loss: 0.505411 [19264/60000]\n",
      "loss: 0.422805 [25664/60000]\n",
      "loss: 0.454380 [32064/60000]\n",
      "loss: 0.457971 [38464/60000]\n",
      "loss: 0.638003 [44864/60000]\n",
      "loss: 0.581691 [51264/60000]\n",
      "loss: 0.412299 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.467871 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.315708 [   64/60000]\n",
      "loss: 0.463912 [ 6464/60000]\n",
      "loss: 0.281773 [12864/60000]\n",
      "loss: 0.503712 [19264/60000]\n",
      "loss: 0.420515 [25664/60000]\n",
      "loss: 0.452968 [32064/60000]\n",
      "loss: 0.456253 [38464/60000]\n",
      "loss: 0.636305 [44864/60000]\n",
      "loss: 0.579972 [51264/60000]\n",
      "loss: 0.411137 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.466720 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.313421 [   64/60000]\n",
      "loss: 0.462490 [ 6464/60000]\n",
      "loss: 0.280348 [12864/60000]\n",
      "loss: 0.502108 [19264/60000]\n",
      "loss: 0.418287 [25664/60000]\n",
      "loss: 0.451527 [32064/60000]\n",
      "loss: 0.454645 [38464/60000]\n",
      "loss: 0.634494 [44864/60000]\n",
      "loss: 0.578385 [51264/60000]\n",
      "loss: 0.409907 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.465594 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.311211 [   64/60000]\n",
      "loss: 0.461002 [ 6464/60000]\n",
      "loss: 0.279039 [12864/60000]\n",
      "loss: 0.500530 [19264/60000]\n",
      "loss: 0.416090 [25664/60000]\n",
      "loss: 0.450119 [32064/60000]\n",
      "loss: 0.453102 [38464/60000]\n",
      "loss: 0.632726 [44864/60000]\n",
      "loss: 0.576937 [51264/60000]\n",
      "loss: 0.408655 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.464493 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.309089 [   64/60000]\n",
      "loss: 0.459514 [ 6464/60000]\n",
      "loss: 0.277772 [12864/60000]\n",
      "loss: 0.498936 [19264/60000]\n",
      "loss: 0.413905 [25664/60000]\n",
      "loss: 0.448652 [32064/60000]\n",
      "loss: 0.451603 [38464/60000]\n",
      "loss: 0.630902 [44864/60000]\n",
      "loss: 0.575394 [51264/60000]\n",
      "loss: 0.407465 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.463410 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.307063 [   64/60000]\n",
      "loss: 0.458056 [ 6464/60000]\n",
      "loss: 0.276582 [12864/60000]\n",
      "loss: 0.497413 [19264/60000]\n",
      "loss: 0.411658 [25664/60000]\n",
      "loss: 0.447216 [32064/60000]\n",
      "loss: 0.450056 [38464/60000]\n",
      "loss: 0.629108 [44864/60000]\n",
      "loss: 0.573909 [51264/60000]\n",
      "loss: 0.406344 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.462342 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.305045 [   64/60000]\n",
      "loss: 0.456616 [ 6464/60000]\n",
      "loss: 0.275361 [12864/60000]\n",
      "loss: 0.495909 [19264/60000]\n",
      "loss: 0.409486 [25664/60000]\n",
      "loss: 0.445782 [32064/60000]\n",
      "loss: 0.448615 [38464/60000]\n",
      "loss: 0.627400 [44864/60000]\n",
      "loss: 0.572399 [51264/60000]\n",
      "loss: 0.405282 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.461298 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.303046 [   64/60000]\n",
      "loss: 0.455168 [ 6464/60000]\n",
      "loss: 0.274166 [12864/60000]\n",
      "loss: 0.494428 [19264/60000]\n",
      "loss: 0.407323 [25664/60000]\n",
      "loss: 0.444424 [32064/60000]\n",
      "loss: 0.447127 [38464/60000]\n",
      "loss: 0.625667 [44864/60000]\n",
      "loss: 0.570888 [51264/60000]\n",
      "loss: 0.404272 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.460270 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.301127 [   64/60000]\n",
      "loss: 0.453772 [ 6464/60000]\n",
      "loss: 0.273005 [12864/60000]\n",
      "loss: 0.492954 [19264/60000]\n",
      "loss: 0.405209 [25664/60000]\n",
      "loss: 0.443102 [32064/60000]\n",
      "loss: 0.445677 [38464/60000]\n",
      "loss: 0.623986 [44864/60000]\n",
      "loss: 0.569371 [51264/60000]\n",
      "loss: 0.403307 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.459258 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.299249 [   64/60000]\n",
      "loss: 0.452350 [ 6464/60000]\n",
      "loss: 0.271907 [12864/60000]\n",
      "loss: 0.491572 [19264/60000]\n",
      "loss: 0.403074 [25664/60000]\n",
      "loss: 0.441861 [32064/60000]\n",
      "loss: 0.444251 [38464/60000]\n",
      "loss: 0.622298 [44864/60000]\n",
      "loss: 0.567918 [51264/60000]\n",
      "loss: 0.402408 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.458264 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.297402 [   64/60000]\n",
      "loss: 0.450911 [ 6464/60000]\n",
      "loss: 0.270828 [12864/60000]\n",
      "loss: 0.490175 [19264/60000]\n",
      "loss: 0.401034 [25664/60000]\n",
      "loss: 0.440547 [32064/60000]\n",
      "loss: 0.442862 [38464/60000]\n",
      "loss: 0.620688 [44864/60000]\n",
      "loss: 0.566405 [51264/60000]\n",
      "loss: 0.401541 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.457285 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.295588 [   64/60000]\n",
      "loss: 0.449469 [ 6464/60000]\n",
      "loss: 0.269785 [12864/60000]\n",
      "loss: 0.488796 [19264/60000]\n",
      "loss: 0.399032 [25664/60000]\n",
      "loss: 0.439292 [32064/60000]\n",
      "loss: 0.441500 [38464/60000]\n",
      "loss: 0.619064 [44864/60000]\n",
      "loss: 0.564887 [51264/60000]\n",
      "loss: 0.400645 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.456319 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.293855 [   64/60000]\n",
      "loss: 0.448070 [ 6464/60000]\n",
      "loss: 0.268740 [12864/60000]\n",
      "loss: 0.487443 [19264/60000]\n",
      "loss: 0.397045 [25664/60000]\n",
      "loss: 0.437999 [32064/60000]\n",
      "loss: 0.440170 [38464/60000]\n",
      "loss: 0.617407 [44864/60000]\n",
      "loss: 0.563374 [51264/60000]\n",
      "loss: 0.399847 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.455370 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.292182 [   64/60000]\n",
      "loss: 0.446684 [ 6464/60000]\n",
      "loss: 0.267744 [12864/60000]\n",
      "loss: 0.486080 [19264/60000]\n",
      "loss: 0.395099 [25664/60000]\n",
      "loss: 0.436675 [32064/60000]\n",
      "loss: 0.438888 [38464/60000]\n",
      "loss: 0.615706 [44864/60000]\n",
      "loss: 0.561859 [51264/60000]\n",
      "loss: 0.399042 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.454428 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.290561 [   64/60000]\n",
      "loss: 0.445332 [ 6464/60000]\n",
      "loss: 0.266776 [12864/60000]\n",
      "loss: 0.484725 [19264/60000]\n",
      "loss: 0.393140 [25664/60000]\n",
      "loss: 0.435354 [32064/60000]\n",
      "loss: 0.437557 [38464/60000]\n",
      "loss: 0.614079 [44864/60000]\n",
      "loss: 0.560376 [51264/60000]\n",
      "loss: 0.398298 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.453505 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.289008 [   64/60000]\n",
      "loss: 0.443962 [ 6464/60000]\n",
      "loss: 0.265773 [12864/60000]\n",
      "loss: 0.483370 [19264/60000]\n",
      "loss: 0.391242 [25664/60000]\n",
      "loss: 0.434051 [32064/60000]\n",
      "loss: 0.436282 [38464/60000]\n",
      "loss: 0.612538 [44864/60000]\n",
      "loss: 0.558866 [51264/60000]\n",
      "loss: 0.397513 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.452592 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.287514 [   64/60000]\n",
      "loss: 0.442595 [ 6464/60000]\n",
      "loss: 0.264798 [12864/60000]\n",
      "loss: 0.482040 [19264/60000]\n",
      "loss: 0.389381 [25664/60000]\n",
      "loss: 0.432815 [32064/60000]\n",
      "loss: 0.435029 [38464/60000]\n",
      "loss: 0.611073 [44864/60000]\n",
      "loss: 0.557403 [51264/60000]\n",
      "loss: 0.396758 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.451691 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.286067 [   64/60000]\n",
      "loss: 0.441278 [ 6464/60000]\n",
      "loss: 0.263864 [12864/60000]\n",
      "loss: 0.480794 [19264/60000]\n",
      "loss: 0.387527 [25664/60000]\n",
      "loss: 0.431549 [32064/60000]\n",
      "loss: 0.433780 [38464/60000]\n",
      "loss: 0.609673 [44864/60000]\n",
      "loss: 0.556002 [51264/60000]\n",
      "loss: 0.396016 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.450799 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.284690 [   64/60000]\n",
      "loss: 0.439943 [ 6464/60000]\n",
      "loss: 0.262975 [12864/60000]\n",
      "loss: 0.479591 [19264/60000]\n",
      "loss: 0.385699 [25664/60000]\n",
      "loss: 0.430303 [32064/60000]\n",
      "loss: 0.432599 [38464/60000]\n",
      "loss: 0.608199 [44864/60000]\n",
      "loss: 0.554648 [51264/60000]\n",
      "loss: 0.395323 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.449916 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.283343 [   64/60000]\n",
      "loss: 0.438556 [ 6464/60000]\n",
      "loss: 0.262102 [12864/60000]\n",
      "loss: 0.478392 [19264/60000]\n",
      "loss: 0.383809 [25664/60000]\n",
      "loss: 0.429067 [32064/60000]\n",
      "loss: 0.431386 [38464/60000]\n",
      "loss: 0.606663 [44864/60000]\n",
      "loss: 0.553299 [51264/60000]\n",
      "loss: 0.394647 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.449036 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.281971 [   64/60000]\n",
      "loss: 0.437179 [ 6464/60000]\n",
      "loss: 0.261217 [12864/60000]\n",
      "loss: 0.477225 [19264/60000]\n",
      "loss: 0.382011 [25664/60000]\n",
      "loss: 0.427918 [32064/60000]\n",
      "loss: 0.430092 [38464/60000]\n",
      "loss: 0.605150 [44864/60000]\n",
      "loss: 0.551963 [51264/60000]\n",
      "loss: 0.393972 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.448164 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.280646 [   64/60000]\n",
      "loss: 0.435761 [ 6464/60000]\n",
      "loss: 0.260351 [12864/60000]\n",
      "loss: 0.476111 [19264/60000]\n",
      "loss: 0.380256 [25664/60000]\n",
      "loss: 0.426735 [32064/60000]\n",
      "loss: 0.428748 [38464/60000]\n",
      "loss: 0.603708 [44864/60000]\n",
      "loss: 0.550723 [51264/60000]\n",
      "loss: 0.393353 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.447312 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.279370 [   64/60000]\n",
      "loss: 0.434433 [ 6464/60000]\n",
      "loss: 0.259456 [12864/60000]\n",
      "loss: 0.474902 [19264/60000]\n",
      "loss: 0.378610 [25664/60000]\n",
      "loss: 0.425560 [32064/60000]\n",
      "loss: 0.427268 [38464/60000]\n",
      "loss: 0.602306 [44864/60000]\n",
      "loss: 0.549521 [51264/60000]\n",
      "loss: 0.392958 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.446480 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.278271 [   64/60000]\n",
      "loss: 0.433152 [ 6464/60000]\n",
      "loss: 0.258563 [12864/60000]\n",
      "loss: 0.473641 [19264/60000]\n",
      "loss: 0.377051 [25664/60000]\n",
      "loss: 0.424334 [32064/60000]\n",
      "loss: 0.425874 [38464/60000]\n",
      "loss: 0.600856 [44864/60000]\n",
      "loss: 0.548124 [51264/60000]\n",
      "loss: 0.392434 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.445659 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.277252 [   64/60000]\n",
      "loss: 0.431870 [ 6464/60000]\n",
      "loss: 0.257724 [12864/60000]\n",
      "loss: 0.472434 [19264/60000]\n",
      "loss: 0.375421 [25664/60000]\n",
      "loss: 0.423201 [32064/60000]\n",
      "loss: 0.424506 [38464/60000]\n",
      "loss: 0.599399 [44864/60000]\n",
      "loss: 0.546790 [51264/60000]\n",
      "loss: 0.391731 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.444832 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.276089 [   64/60000]\n",
      "loss: 0.430529 [ 6464/60000]\n",
      "loss: 0.256899 [12864/60000]\n",
      "loss: 0.471247 [19264/60000]\n",
      "loss: 0.373797 [25664/60000]\n",
      "loss: 0.422000 [32064/60000]\n",
      "loss: 0.423303 [38464/60000]\n",
      "loss: 0.598071 [44864/60000]\n",
      "loss: 0.545556 [51264/60000]\n",
      "loss: 0.391076 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.444015 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.274861 [   64/60000]\n",
      "loss: 0.429185 [ 6464/60000]\n",
      "loss: 0.256117 [12864/60000]\n",
      "loss: 0.470053 [19264/60000]\n",
      "loss: 0.372195 [25664/60000]\n",
      "loss: 0.420805 [32064/60000]\n",
      "loss: 0.422103 [38464/60000]\n",
      "loss: 0.596778 [44864/60000]\n",
      "loss: 0.544284 [51264/60000]\n",
      "loss: 0.390433 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.443204 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.273678 [   64/60000]\n",
      "loss: 0.427932 [ 6464/60000]\n",
      "loss: 0.255356 [12864/60000]\n",
      "loss: 0.468795 [19264/60000]\n",
      "loss: 0.370600 [25664/60000]\n",
      "loss: 0.419676 [32064/60000]\n",
      "loss: 0.420937 [38464/60000]\n",
      "loss: 0.595467 [44864/60000]\n",
      "loss: 0.543003 [51264/60000]\n",
      "loss: 0.389859 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.442418 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.272542 [   64/60000]\n",
      "loss: 0.426627 [ 6464/60000]\n",
      "loss: 0.254611 [12864/60000]\n",
      "loss: 0.467605 [19264/60000]\n",
      "loss: 0.369069 [25664/60000]\n",
      "loss: 0.418560 [32064/60000]\n",
      "loss: 0.419823 [38464/60000]\n",
      "loss: 0.594100 [44864/60000]\n",
      "loss: 0.541716 [51264/60000]\n",
      "loss: 0.389313 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.441643 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.271439 [   64/60000]\n",
      "loss: 0.425337 [ 6464/60000]\n",
      "loss: 0.253906 [12864/60000]\n",
      "loss: 0.466392 [19264/60000]\n",
      "loss: 0.367541 [25664/60000]\n",
      "loss: 0.417483 [32064/60000]\n",
      "loss: 0.418741 [38464/60000]\n",
      "loss: 0.592730 [44864/60000]\n",
      "loss: 0.540488 [51264/60000]\n",
      "loss: 0.388789 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.440878 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.270344 [   64/60000]\n",
      "loss: 0.424034 [ 6464/60000]\n",
      "loss: 0.253227 [12864/60000]\n",
      "loss: 0.465158 [19264/60000]\n",
      "loss: 0.366104 [25664/60000]\n",
      "loss: 0.416418 [32064/60000]\n",
      "loss: 0.417631 [38464/60000]\n",
      "loss: 0.591384 [44864/60000]\n",
      "loss: 0.539235 [51264/60000]\n",
      "loss: 0.388287 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.440120 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.269290 [   64/60000]\n",
      "loss: 0.422787 [ 6464/60000]\n",
      "loss: 0.252564 [12864/60000]\n",
      "loss: 0.463942 [19264/60000]\n",
      "loss: 0.364637 [25664/60000]\n",
      "loss: 0.415365 [32064/60000]\n",
      "loss: 0.416571 [38464/60000]\n",
      "loss: 0.590115 [44864/60000]\n",
      "loss: 0.537960 [51264/60000]\n",
      "loss: 0.387831 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.439369 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.268275 [   64/60000]\n",
      "loss: 0.421530 [ 6464/60000]\n",
      "loss: 0.251895 [12864/60000]\n",
      "loss: 0.462721 [19264/60000]\n",
      "loss: 0.363229 [25664/60000]\n",
      "loss: 0.414297 [32064/60000]\n",
      "loss: 0.415539 [38464/60000]\n",
      "loss: 0.588814 [44864/60000]\n",
      "loss: 0.536735 [51264/60000]\n",
      "loss: 0.387379 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.438622 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.267315 [   64/60000]\n",
      "loss: 0.420272 [ 6464/60000]\n",
      "loss: 0.251251 [12864/60000]\n",
      "loss: 0.461488 [19264/60000]\n",
      "loss: 0.361835 [25664/60000]\n",
      "loss: 0.413245 [32064/60000]\n",
      "loss: 0.414505 [38464/60000]\n",
      "loss: 0.587568 [44864/60000]\n",
      "loss: 0.535512 [51264/60000]\n",
      "loss: 0.386902 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.437876 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.266379 [   64/60000]\n",
      "loss: 0.418975 [ 6464/60000]\n",
      "loss: 0.250633 [12864/60000]\n",
      "loss: 0.460265 [19264/60000]\n",
      "loss: 0.360480 [25664/60000]\n",
      "loss: 0.412212 [32064/60000]\n",
      "loss: 0.413527 [38464/60000]\n",
      "loss: 0.586314 [44864/60000]\n",
      "loss: 0.534280 [51264/60000]\n",
      "loss: 0.386430 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.437141 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.265451 [   64/60000]\n",
      "loss: 0.417715 [ 6464/60000]\n",
      "loss: 0.250024 [12864/60000]\n",
      "loss: 0.459070 [19264/60000]\n",
      "loss: 0.359168 [25664/60000]\n",
      "loss: 0.411160 [32064/60000]\n",
      "loss: 0.412503 [38464/60000]\n",
      "loss: 0.585075 [44864/60000]\n",
      "loss: 0.533112 [51264/60000]\n",
      "loss: 0.385955 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.436412 \n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 50\n",
    "target_accuracy = 0.9\n",
    "for t in range(max_epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_accuracy = test(test_dataloader, model, loss_fn)\n",
    "    if test_accuracy >= target_accuracy:\n",
    "        break\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to {save_path}\n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "save_path = \"model/model.pth\"\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print(\"Saved PyTorch Model State to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flattern): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "model = NeuralNetwork().to(device)\n",
    "model.load_state_dict(torch.load(save_path))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    x = x.to(device)\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
